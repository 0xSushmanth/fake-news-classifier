{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Faux Filter\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras_preprocessing.text import one_hot  # Converting to one-hot repr.\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:49:17.297803500Z",
     "start_time": "2023-05-15T04:48:35.115635200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading data from csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                              title              author  \\\n0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n\n                                                text  label  \n0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n1  Ever get the feeling your life circles the rou...      0  \n2  Why the Truth Might Get You Fired October 29, ...      1  \n3  Videos 15 Civilians Killed In Single US Airstr...      1  \n4  Print \\nAn Iranian woman has been sentenced to...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>Darrell Lucus</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n      <td>Daniel J. Flynn</td>\n      <td>Ever get the feeling your life circles the rou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why the Truth Might Get You Fired</td>\n      <td>Consortiumnews.com</td>\n      <td>Why the Truth Might Get You Fired October 29, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n      <td>Jessica Purkiss</td>\n      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian woman jailed for fictional unpublished...</td>\n      <td>Howard Portnoy</td>\n      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from csv\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:26.491888500Z",
     "start_time": "2023-05-15T04:50:25.098109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              title  \\\n0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n1  20801  Russian warships ready to strike terrorists ne...   \n2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n4  20804                    Keiser Report: Meme Wars (E995)   \n\n                    author                                               text  \n0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n1                      NaN  Russian warships ready to strike terrorists ne...  \n2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n3            Daniel Victor  If at first you don’t succeed, try a different...  \n4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20800</td>\n      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n      <td>David Streitfeld</td>\n      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20801</td>\n      <td>Russian warships ready to strike terrorists ne...</td>\n      <td>NaN</td>\n      <td>Russian warships ready to strike terrorists ne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20802</td>\n      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n      <td>Common Dreams</td>\n      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20803</td>\n      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n      <td>Daniel Victor</td>\n      <td>If at first you don’t succeed, try a different...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20804</td>\n      <td>Keiser Report: Meme Wars (E995)</td>\n      <td>Truth Broadcast Network</td>\n      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:27.152980700Z",
     "start_time": "2023-05-15T04:50:27.129970400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20800 number of rows and 5 number of columns for training.\n",
      "There are 5200 number of rows and 4 number of columns for testing.\n"
     ]
    }
   ],
   "source": [
    "# Displaying rows and columns in dataset\n",
    "print(\"There are {} number of rows and {} number of columns for training.\".format(train.shape[0],train.shape[1]))\n",
    "print(\"There are {} number of rows and {} number of columns for testing.\".format(test.shape[0],test.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:27.753134600Z",
     "start_time": "2023-05-15T04:50:27.744127300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking Null Values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "id           0\ntitle      558\nauthor    1957\ntext        39\nlabel        0\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in training data.\n",
    "train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:28.744426300Z",
     "start_time": "2023-05-15T04:50:28.727423Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "id          0\ntitle     122\nauthor    503\ntext        7\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in testing data.\n",
    "test.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:29.202668500Z",
     "start_time": "2023-05-15T04:50:29.184261Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handling nan values in dataset using empty spaces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def handle_nan(train_data,test_data):\n",
    "    '''Input: Data to the function containing Nan values.\n",
    "       Output : Cleaned data containing no Nan values.\n",
    "       Function: Cleaning Nan values.\n",
    "     '''\n",
    "    train = train_data.fillna(\" \")\n",
    "    test  = test_data.fillna(\" \")\n",
    "    return train,test\n",
    "\n",
    "train,test = handle_nan(train,test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:30.073064400Z",
     "start_time": "2023-05-15T04:50:30.047054400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Creating a variable \"merged\" by merging columns \"title\" and \"author\"\n",
    "train[\"merged\"] = train[\"title\"]+\" \"+train[\"author\"]\n",
    "test[\"merged\"]  = test[\"title\"]+\" \"+test[\"author\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:30.707192Z",
     "start_time": "2023-05-15T04:50:30.675184400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Seperating Independent and dependent features\n",
    "X = train.drop(columns=['label'],axis=1)\n",
    "y = train['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:31.094603100Z",
     "start_time": "2023-05-15T04:50:31.069597400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Creating One-Hot Representations\n",
    "messages = X.copy()\n",
    "messages.reset_index(inplace=True)\n",
    "messages_test = test.copy()\n",
    "messages_test.reset_index(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:50:31.448098900Z",
     "start_time": "2023-05-15T04:50:31.425096100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-processing\n",
    "**1. Firstly, we will process and use stopwords.**\n",
    "**2. Next, to avoid false predictions or ambiguity with upper and lowercase, we will convert them to lowercase.**\n",
    "**3. Next, all the sentences are tokenized into words.**\n",
    "**4. We will use stemming to the tokenized words for quick preprocessing.**\n",
    "**5. Next, words are joined together and stored in the corpus.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'flynn hillari clinton big woman campu breitbart daniel j flynn'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing data preprocessing on column 'title'\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def perform_preprocess(data):\n",
    "    '''Input: Data to be processed\n",
    "       Output: Preprocessed data\n",
    "    '''\n",
    "    corpus = []\n",
    "    for i in range(0,len(data)):\n",
    "        review = re.sub('[^a-zA-Z]',' ',data['merged'][i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "    \n",
    "train_corpus = perform_preprocess(messages)\n",
    "test_corpus  = perform_preprocess(messages_test)\n",
    "train_corpus[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.623089200Z",
     "start_time": "2023-05-15T04:50:32.078469400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'russian warship readi strike terrorist near aleppo'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.639834100Z",
     "start_time": "2023-05-15T04:51:44.624090100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Below code converts the pre-processed words to one-hot vectors in the range of vocabulary size=5000. This is done to obtain numerical feature matrix**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "one_hot_train = [one_hot(word,vocab_size) for word in train_corpus]\n",
    "one_hot_test  = [one_hot(word,vocab_size) for word in test_corpus]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.878043300Z",
     "start_time": "2023-05-15T04:51:44.638833200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[13, 2490, 4053, 3019, 1484, 1580, 2077]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.893605500Z",
     "start_time": "2023-05-15T04:51:44.879043600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Below code creates an embedding layer which applies \"pre\" padding to the one-hot encoded features with sentence length = 20. Padding is applied so that the length of every sequence in the dataset should be same.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  464 3314 3273]\n",
      " [   0    0    0 ... 2336 2316 2209]\n",
      " [   0    0    0 ... 3417 2409 3837]\n",
      " ...\n",
      " [   0    0    0 ... 2828 2370 3231]\n",
      " [   0    0    0 ... 1523 4923 3199]\n",
      " [   0    0    0 ... 3704   53 2577]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Embedding Representation\n",
    "sent_length = 20\n",
    "embedd_docs_train = pad_sequences(one_hot_train,padding='pre',maxlen=sent_length)\n",
    "embedd_docs_test  = pad_sequences(one_hot_test,padding='pre',maxlen=sent_length)\n",
    "print(embedd_docs_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.955730100Z",
     "start_time": "2023-05-15T04:51:44.892605100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 3141   53 4114]\n",
      " [   0    0    0 ... 1484 1580 2077]\n",
      " [   0    0    0 ... 3165 4231  882]\n",
      " ...\n",
      " [   0    0    0 ... 3141 4900 2798]\n",
      " [   0    0    0 ...   13  416 2269]\n",
      " [   0    0    0 ... 3141 2964 4385]]\n"
     ]
    }
   ],
   "source": [
    "print(embedd_docs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:44.971999500Z",
     "start_time": "2023-05-15T04:51:44.957730400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Converting Embedding repr. to array\n",
    "x_final = np.array(embedd_docs_train)\n",
    "y_final = np.array(y)\n",
    "x_test_final = np.array(embedd_docs_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.032141800Z",
     "start_time": "2023-05-15T04:51:44.972999400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "((20800, 20), (20800,), (5200, 20))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of prev. array repr.\n",
    "x_final.shape,y_final.shape,x_test_final.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.040143100Z",
     "start_time": "2023-05-15T04:51:44.988132600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Split into Test and Train.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.1, random_state=42, stratify = y_final)\n",
    "X_train, x_valid, Y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42, stratify = y_train)\n",
    "x_test_final = x_test_final"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.041143200Z",
     "start_time": "2023-05-15T04:51:45.004135700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create CountVectorizer object\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "\n",
    "# fit_transform on train data\n",
    "x_train_cv = cv.fit_transform(train_corpus).toarray()\n",
    "\n",
    "# transform on test data\n",
    "x_test_cv = cv.transform(test_corpus).toarray()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.444002600Z",
     "start_time": "2023-05-15T04:51:45.037143400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Models\n",
    "**In this phase, several models are created and evaluated against various metrics shown using classification report.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Logistic Regresssion**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Logistic Regression: A linear model that uses a logistic function to model the probability of a binary response variable. It is commonly used for binary classification problems, but can also be extended to multi-class classification problems.**\n",
    "\n",
    "**The logistic regression model predicts the probability of a binary response variable (y) given a set of input features (x) using the logistic function:\n",
    "p(y=1|x) = 1 / (1 + exp(-z))\n",
    "where z = b0 + b1x1 + b2x2 + ... + bn*xn is the linear combination of the input features and their corresponding weights (b0, b1, b2, ..., bn).\n",
    "The weights are estimated from the training data using maximum likelihood estimation or other optimization techniques.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1039\n",
      "           1       0.73      0.69      0.71      1041\n",
      "\n",
      "    accuracy                           0.72      2080\n",
      "   macro avg       0.72      0.72      0.72      2080\n",
      "weighted avg       0.72      0.72      0.72      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model with a maximum of 900 iterations\n",
    "model_1 = LogisticRegression(max_iter=900)\n",
    "\n",
    "# Train the model on the training data\n",
    "model_1.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "pred_1 = model_1.predict(x_test)\n",
    "\n",
    "# Generate a classification report to evaluate the performance of the model\n",
    "cr1 = classification_report(y_test, pred_1)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(cr1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.569868300Z",
     "start_time": "2023-05-15T04:51:45.444002600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Naive Bayes**\n",
    "**A probabilistic model that uses Bayes' theorem to predict the probability of a class given a set of features. It is commonly used for text classification problems, where the features are the frequencies of words in a document.**\n",
    "\n",
    "**The Naive Bayes model predicts the probability of a binary response variable (y) given a set of input features (x) using Bayes' theorem:\n",
    "p(y=1|x) = p(x|y=1) * p(y=1) / p(x)\n",
    "where p(x|y=1) is the likelihood of the input features given the positive class, p(y=1) is the prior probability of the positive class, and p(x) is the marginal probability of the input features.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      1039\n",
      "           1       0.69      0.76      0.72      1041\n",
      "\n",
      "    accuracy                           0.71      2080\n",
      "   macro avg       0.71      0.71      0.71      2080\n",
      "weighted avg       0.71      0.71      0.71      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes model\n",
    "model_2 = MultinomialNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_2.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "pred_2 = model_2.predict(x_test)\n",
    "\n",
    "# Generate a classification report to evaluate the performance of the model\n",
    "cr2 = classification_report(y_test, pred_2)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(cr2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.632043400Z",
     "start_time": "2023-05-15T04:51:45.570867900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Decision Trees**\n",
    "**A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label. It recursively splits the data into subsets based on the values of the features, and assigns a class label to each leaf node.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1039\n",
      "           1       0.95      0.93      0.94      1041\n",
      "\n",
      "    accuracy                           0.94      2080\n",
      "   macro avg       0.94      0.94      0.94      2080\n",
      "weighted avg       0.94      0.94      0.94      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Decision Tree Classifier model\n",
    "model_3 = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_3.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "pred_3 = model_3.predict(x_test)\n",
    "\n",
    "# Generate a classification report to evaluate the performance of the model\n",
    "cr3 = classification_report(y_test, pred_3)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(cr3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:45.805080500Z",
     "start_time": "2023-05-15T04:51:45.632043400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Random Forest**\n",
    "**An ensemble model(An ensemble model is a machine learning model that combines multiple individual models to improve the accuracy and robustness of the predictions.) that combines multiple decision trees to improve the accuracy and robustness of the predictions. It randomly selects a subset of features and data points for each tree, and aggregates the predictions of all the trees to make the final prediction.An ensemble model that combines multiple decision trees to improve the accuracy and robustness of the predictions. It randomly selects a subset of features and data points for each tree, and aggregates the predictions of all the trees to make the final prediction.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The prediction of a random forest model can be represented by the following formula:\n",
    "y = mode(y1, y2, ..., yn)\n",
    "where y1, y2, ..., yn are the predictions of the individual trees, and mode() is the function that returns the most common prediction.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1039\n",
      "           1       0.87      0.97      0.92      1041\n",
      "\n",
      "    accuracy                           0.92      2080\n",
      "   macro avg       0.92      0.92      0.92      2080\n",
      "weighted avg       0.92      0.92      0.92      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier model\n",
    "model_4 = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_4.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "pred_4 = model_4.predict(x_test)\n",
    "\n",
    "# Generate a classification report to evaluate the performance of the model\n",
    "cr4 = classification_report(y_test, pred_4)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(cr4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:48.776266100Z",
     "start_time": "2023-05-15T04:51:45.807080800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5. XGBOOST**\n",
    "**An optimized implementation of gradient boosting(Gradient Boosting is a machine learning technique that combines multiple weak models to create a strong predictive model) that uses a combination of tree-based models and linear models to improve the accuracy and speed of the predictions. It uses a gradient descent algorithm to iteratively improve the predictions by minimizing a loss function.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The prediction of an XGBoost model can be represented by the following formula:\n",
    "y = sum(wi * yi)\n",
    "where wi is the weight of the i-th tree, and yi is the prediction of the i-th tree. The weights and predictions are determined by the gradient descent algorithm, which minimizes a loss function that measures the difference between the predicted and actual values**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1039\n",
      "           1       0.98      1.00      0.99      1041\n",
      "\n",
      "    accuracy                           0.99      2080\n",
      "   macro avg       0.99      0.99      0.99      2080\n",
      "weighted avg       0.99      0.99      0.99      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost Classifier model\n",
    "model_5 = XGBClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_5.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "pred_5 = model_5.predict(x_test)\n",
    "\n",
    "# Generate a classification report to evaluate the performance of the model\n",
    "cr5 = classification_report(y_test, pred_5)\n",
    "\n",
    "# Print the classification report to the console\n",
    "print(cr5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:51:49.192359200Z",
     "start_time": "2023-05-15T04:51:48.776266100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tabulating the results of various implemented models.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Saving Model**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_5,open('model.pkl','wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T04:55:02.861431400Z",
     "start_time": "2023-05-15T04:55:02.826424600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
